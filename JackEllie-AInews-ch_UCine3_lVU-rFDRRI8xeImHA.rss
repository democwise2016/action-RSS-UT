<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">
  <channel>
    <title><![CDATA[杰克艾米立 AI大小事[YT+]]]></title>
    <link>http://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA</link>
    <image>
      <url>https://yt3.googleusercontent.com/0xMEZnqzcaxKGw0rz4aO2N3v-eRR8X-SQCESGqFCTzg4RQZxqhoAm9nj1UCKPbm2oJQ0zAM=s900-b50-c-k-c0x008A95A5-no-rj</url>
      <title>杰克艾米立 AI大小事[YT+]</title>
      <link>http://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA</link>
    </image>
    <language>en-us</language>
    <atom:link href="https://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA" rel="self" type="application/rss+xml"/>
    <copyright><![CDATA[杰克艾米立 AI大小事[YT+]]]></copyright>
    <itunes:author><![CDATA[杰克艾米立 AI大小事[YT+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[
      <a href="https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA" target="_blank">https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA</a><br />
<br />
<a href="https://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA" target="_blank">https://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA</a>
      ]]>
    </itunes:summary>
    <description>
      <![CDATA[
      <a href="https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA" target="_blank">https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA</a><br />
<br />
<a href="https://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA" target="_blank">https://www.youtube.com/feeds/videos.xml?channel_id=UCine3_lVU-rFDRRI8xeImHA</a>
      ]]>
    </description>
    <itunes:owner>
      <itunes:name><![CDATA[杰克艾米立 AI大小事[YT+]]]></itunes:name>
    </itunes:owner>
    <itunes:image href="https://yt3.googleusercontent.com/0xMEZnqzcaxKGw0rz4aO2N3v-eRR8X-SQCESGqFCTzg4RQZxqhoAm9nj1UCKPbm2oJQ0zAM=s900-b50-c-k-c0x008A95A5-no-rj"/>
<item>
      <title><![CDATA[2024年最好的開源模型Flux磅礡登場!!付6GVRAM使用說明書]]></title>
      <link>https://www.youtube.com/watch?v=Nrkh_E6iuwA</link>
      <itunes:title><![CDATA[2024年最好的開源模型Flux磅礡登場!!付6GVRAM使用說明書]]></itunes:title>
      <itunes:author><![CDATA[杰克艾米立]]></itunes:author>
      <itunes:summary>
        <![CDATA[<hr style="clear:both" />

<p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><h1>引言：Stability AI的風波與Flux模型的誕生</h1>杰克與艾粒向觀眾們問好，並回顧了Stability AI因SD3模型遭遇的社群反彈與內部動盪。然而，他們很快便成立了黑森林工作室，並推出開源世界中體積龐大的Flux模型。Flux模型在性能和提詞控制上表現優異，超越了先前的模型，但因為其對VRAM的高要求，讓許多使用者難以使用。<h1>Flux模型的現況：6G VRAM也能玩</h1>幸運的是，貓神伊利維亞斯在8月11日釋出了壓縮版的Flux模型，並更新了Forge，使得Flux模型現在可以在6G VRAM的環境下運行。本影片將詳細介紹如何使用這個模型。<h1>抽獎活動與書籍推薦</h1>在開始之前，主持人宣布將抽出《超有料！職場第一實用的 AI 工作術》這本書，該書深入探討了如何利用AI解決辦公室中的各種問題，提升工作效率。<h1>Forge的安裝與更新</h1>由於Forge先前停止更新，導致許多擴充功能無法正常使用，影片中介紹了更新後的Forge安裝方法，以及如何下載與更新Flux模型。安裝Forge的懶人包已更新，可以在影片下方找到下載連結，並提供了擴充功能的資訊和共享模型的指令。如果對操作不熟悉，可以參考之前的Forge影片。<h1>Flux模型的下載與存放</h1>影片詳細說明了Flux模型的下載與存放路徑。目前提供FP8和NF4兩種格式，雖然貓神建議30、40系列顯卡使用NF4格式，其他顯卡使用FP8格式，但實際測試中，10、20系列的顯卡也能在NF4格式下運行。考慮到NF4格式對VRAM的需求較低，且在低階顯卡上加速效果顯著，因此影片建議優先使用NF4格式，真的不行再改用FP8格式。此外，也提到了GGUF格式，但由於使用較為複雜，需要額外下載文本編碼器和VAE，因此建議有興趣的觀眾到DC群中查看相關的使用文章。<h1>Flux模型的使用介紹</h1>影片詳細介紹了如何在Forge中設定和使用Flux模型。*   **模型權重存檔點介面：** 說明如何在Forge的介面中選擇Flux模型，以及選擇Diffusion with Low Bits模型。*   **儲存格式：** 依照硬體與需求選擇儲存格式，這將影響繪圖時間和圖像變化。*   **Swap Method：** 分別介紹了Asyne (快速但可能耗用過多VRAM) 和 Queue (穩定排隊計算) 兩種 RAM 與 VRAM 間的交換方式，建議根據硬體狀況選擇。*   **Swap Location：** 說明在低VRAM硬體上，使用共享記憶體交換或CPU交換，並提供了選擇的建議。*   **GPU Weights (MB)：** 調整模型使用的VRAM空間，以適應不同的硬體，並平衡繪圖速度和VRAM的使用。*   **取樣方法：** 建議使用原始設定的Euler 和simple(單一值)或與DPM++2M 和SGM Uniform交互使用。*   **提示詞相關性 CFG：** 因為Flux是蒸餾模型，並不適用CFG，建議使用Distilled CFG Scale。<h1>總結</h1>Flux模型在社群的努力下，即使模型體積龐大，也能在低階硬體上運行。影片鼓勵觀眾嘗試，並在Discord上舉辦抽獎活動。艾粒也透露，他們正在學習使用GPT和Blender。<hr />================================================</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><strong># 片頭</strong></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_17.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=17" target="_blank"><strong># 簡介</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">大家好我是杰克。大家好我是艾粒。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相信前陣子。大家都有吃到Stablity AI的瓜。SD3大鍋一砸。不但社群不買單。公司內部的大佬們也紛紛離開。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過還好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">他們很快的。成立了一間黑森林工作室。並釋出了第一個目前在開源世界中。最巨大的模型Flux。這個模型的性能非常優秀。提詞控制效果也很強。建築結構。人物肢體等等。都遠勝於之前的模型。既然他這麼優秀。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">為什麼我們之前沒有介紹呢。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為flux模型非常大。所以VRAM要求也就提高了。但!!貓神伊利維亞斯在8月11號時。發布了經過壓縮的flux。並更新了forge的版本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">現在flux可以在6G VRAM上運作了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">當然要來好好介紹一下使用方法啦。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_78.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=78" target="_blank"><strong># 抽書活動</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">喔。一樣在開始之前。我們來抽書吧。這次是這本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">超有料！職場第一實用的 AI 工作術。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">用對工具讓生產力全面進化。看完這本書你再也不需要擔心。DPF檔原文Paper無法全文翻譯。會議記錄做起來費時又費力。E-mail和信息堆積了一大堆。這些都能靠AI解決。還能讓AI幫忙解釋法律用語。將數據可視化。還能在夜深人靜的時候。陪你喝心靈雞湯。AI現在已經無所不在。記得看到最後喔。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_117.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=117" target="_blank"><strong># 安裝forge</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">安裝。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">首先我們來安裝Forge吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為之前Forge停更了一段時間。導致許多功能都不能正常使用。所以Forge安裝篇的懶人包。已經變成Reforge懶人包了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Forge懶人包就這篇的底下。那就開始安裝吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到影片下方說明。找到懶人包下載文件。裡面有懶人包載點。跟目前已知沒有受影響的擴充。還有共享模型的命令。都在裡面自己看一下吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">如果不清楚怎麼用。可以參考之前的forge影片。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">下載完成後。跟我們介紹過的所有懶人包一樣。點選update更新。等系統出現請按任意鍵繼續的提示後關閉。未來要執行只需要點選run就好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過因為啟動後會自動下載模型。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">所以我們先去下載flux模型。之後放好再點run。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">另外如果你本來就有安裝forge。更新到最新版本後。會發現有些擴充不能用了。記得先整理一下。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_179.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=179" target="_blank"><strong># Flux模型下載</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">模型下載與存放路徑。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到下方說明下載經過壓縮的Flux模型。目前有兩種格式一種是FP8。另一個是NF4。雖然貓神表示如果你的顯卡是30、40系列。才能使用NF4格式。其餘的應該要下載FP8格式。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">但我們依然有看到10、20系列的顯卡。成功在NF4格式上使用的案例。再加上NF4格式VRAM需求較低。而且在比較低階的顯卡上。加速效果相當明顯。所以我們一律推薦各位使用NF4格式。真的不能使用再改用FP8格式。載好後放到以下路徑吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">對了。其實還有另一種GGUF格式。但因為需要另外下載文本編碼器跟VAE。使用起來比較麻煩。有興趣的可以到DC群中。看一下我寫的使用文章。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_236.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=236" target="_blank"><strong># Flux使用介紹</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">flux使用介紹。把Forge更新到最新版本後。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">會看到介面最上面一列。選擇模型權重存檔點的介面有改動。只要選擇UI的類型。就能知道有哪些參數需要調整。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">點選Flux。接著選擇剛剛下載的模型。Diffusion with Low Bits. 依照硬體和需求選擇儲存格式。依選擇的格式會有很大的時間差距。和些許的圖像變化。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Swap Method. 這是RAM與VRAM之間的交換方式。Asyne的速度較快。但有可能會在運作中使用過多的VRAM。從而進入共用記憶體。導致運算速度劇烈下滑。而Queue的運算方式。則是穩定的讓每一層排隊逐個進行計算。這邊我選Queue。若是還有遇到其他問題。建議到下方說明中。依利維亞斯的github上。看一下除錯方法。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_300.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再來是Swap Location。因為模型很大。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">在低vram硬體下。不足以承載模型。需要用到CPU或共用記憶體來幫忙。經過作者測試。在較新的硬體上。選擇共用記憶體交換。比使用CPU快上約百分之15。但若是系統崩潰。則建議選擇CPU交換。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">最後看到GPU Weights (MB)。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">這邊可以調整模型使用的VRAM空間。降低GPU Weights以確保繪製圖像時。有足夠的VRAM可以使用。讓低VRAM的設備。有機會挑戰更大張的圖像。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過算圖的速度也會下降。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">想要提高運算速度的話。就提高GPU Weights。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相對地若是調太高。在算圖時VRAM不夠的話。就會進到共用記憶體。大幅的拉低運算速度。這邊就依照自己的設備進行調整吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">接著看到取樣方法這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">使用原始設定的Euler 和simple(單一值)就好。或是和DPM++2M。跟SGM Uniform交互使用。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_368.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再往下看到提示詞相關性CFG這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為Flux是蒸餾模型。事實上這類模型在訓練時。並不包含CFG這類相關指標。且不適用反向提示詞。所以在繪圖時也不建議開啟。畢竟沒有效果。又要花上雙倍的時間運算。取而代之的是Distilled CFG Scale。他僅僅是稍微的改變了色澤。和些許構圖。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_402.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=402" target="_blank"><strong># 結尾</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">儘管這類模型在訓練上的硬體要求很高。社群的大家還是迅速的。訓練出各種模型。在C站上也相當的熱鬧。是個非常有展望的模型。所以說。不要怕模型太大大家沒辦法用。只要敢放出來。社群的大家。就有辦法能讓模型在馬鈴薯上運作。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">那這次的抽獎。一樣在影片上架的同時。在Discord上舉辦。如果想知道現在。大家都是怎麼拿AI來工作的。千萬不要錯過喔。艾粒現在也在跟GPT學習Blender呢。那就這樣啦。掰。</p>

<hr style="clear:both" />
====
<p>https://www.youtube.com/watch?v=Nrkh_E6iuwA</p><p>本篇為Flux的使用教學，由於flux是一個非常巨大的模型導致許多設備無法使用，在貓神lllyasviel發起的NF4格式中成功的將模型進行了大幅度的壓縮，並且在6GVRAM的設備上也能運行，快來從forge上運行Flux模型體驗新世代模型的表現能力吧。</p><p>加入Discord: https://discord.gg/TM5d89YNwA</p><p>FB粉專: https://www.facebook.com/profile.php?id=100090228987264 </p><p>成為這個頻道的會員並獲得福利： https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA/join </p><p>抖內JackEllie(本功能沒有任何福利，但謝謝你的錢): https://www.buymeacoffee.com/otakuya202y =====================================================================</p><p></p><p>0:00片頭</p><p>0:17 簡介</p><p>1:18 抽書活動</p><p>1:57 安裝forge</p><p>2:59 Flux模型下載</p><p>3:56 Flux使用介紹</p><p>6:42 結尾</p><p>7:20 片尾</p><p></p><p>=====================================================================</p><p>Forge懶人包安裝文件:</p><p>https://drive.google.com/file/d/1-2oxHAc8oJmkOhHw6O3XgtgeyMGZIKZC/view?usp=sharing</p><p></p><p>Flux模型載點</p><p>NF4格式:</p><p>https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/resolve/main/flux1-dev-bnb-nf4-v2.safetensors</p><p></p><p>FP8格式:</p><p>https://huggingface.co/lllyasviel/flux1_dev/resolve/main/flux1-dev-fp8.safetensors?download=true</p><p></p><p>GGUF格式請上Discord看教學文章</p><p>https://discord.com/channels/1077423770106597386/1273894421922058324</p><p></p><p>原文使用教學</p><p>https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981</p><p></p><p>#stablediffusion #aidrawing #ai繪圖 #aiart #aigc #SD3 #flux #nf4 #fp8 #gguf</p>]]>
      </itunes:summary>
      <description>
        <![CDATA[<hr style="clear:both" />

<p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><h1>引言：Stability AI的風波與Flux模型的誕生</h1>杰克與艾粒向觀眾們問好，並回顧了Stability AI因SD3模型遭遇的社群反彈與內部動盪。然而，他們很快便成立了黑森林工作室，並推出開源世界中體積龐大的Flux模型。Flux模型在性能和提詞控制上表現優異，超越了先前的模型，但因為其對VRAM的高要求，讓許多使用者難以使用。<h1>Flux模型的現況：6G VRAM也能玩</h1>幸運的是，貓神伊利維亞斯在8月11日釋出了壓縮版的Flux模型，並更新了Forge，使得Flux模型現在可以在6G VRAM的環境下運行。本影片將詳細介紹如何使用這個模型。<h1>抽獎活動與書籍推薦</h1>在開始之前，主持人宣布將抽出《超有料！職場第一實用的 AI 工作術》這本書，該書深入探討了如何利用AI解決辦公室中的各種問題，提升工作效率。<h1>Forge的安裝與更新</h1>由於Forge先前停止更新，導致許多擴充功能無法正常使用，影片中介紹了更新後的Forge安裝方法，以及如何下載與更新Flux模型。安裝Forge的懶人包已更新，可以在影片下方找到下載連結，並提供了擴充功能的資訊和共享模型的指令。如果對操作不熟悉，可以參考之前的Forge影片。<h1>Flux模型的下載與存放</h1>影片詳細說明了Flux模型的下載與存放路徑。目前提供FP8和NF4兩種格式，雖然貓神建議30、40系列顯卡使用NF4格式，其他顯卡使用FP8格式，但實際測試中，10、20系列的顯卡也能在NF4格式下運行。考慮到NF4格式對VRAM的需求較低，且在低階顯卡上加速效果顯著，因此影片建議優先使用NF4格式，真的不行再改用FP8格式。此外，也提到了GGUF格式，但由於使用較為複雜，需要額外下載文本編碼器和VAE，因此建議有興趣的觀眾到DC群中查看相關的使用文章。<h1>Flux模型的使用介紹</h1>影片詳細介紹了如何在Forge中設定和使用Flux模型。*   **模型權重存檔點介面：** 說明如何在Forge的介面中選擇Flux模型，以及選擇Diffusion with Low Bits模型。*   **儲存格式：** 依照硬體與需求選擇儲存格式，這將影響繪圖時間和圖像變化。*   **Swap Method：** 分別介紹了Asyne (快速但可能耗用過多VRAM) 和 Queue (穩定排隊計算) 兩種 RAM 與 VRAM 間的交換方式，建議根據硬體狀況選擇。*   **Swap Location：** 說明在低VRAM硬體上，使用共享記憶體交換或CPU交換，並提供了選擇的建議。*   **GPU Weights (MB)：** 調整模型使用的VRAM空間，以適應不同的硬體，並平衡繪圖速度和VRAM的使用。*   **取樣方法：** 建議使用原始設定的Euler 和simple(單一值)或與DPM++2M 和SGM Uniform交互使用。*   **提示詞相關性 CFG：** 因為Flux是蒸餾模型，並不適用CFG，建議使用Distilled CFG Scale。<h1>總結</h1>Flux模型在社群的努力下，即使模型體積龐大，也能在低階硬體上運行。影片鼓勵觀眾嘗試，並在Discord上舉辦抽獎活動。艾粒也透露，他們正在學習使用GPT和Blender。<hr />================================================</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><strong># 片頭</strong></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_17.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=17" target="_blank"><strong># 簡介</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">大家好我是杰克。大家好我是艾粒。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相信前陣子。大家都有吃到Stablity AI的瓜。SD3大鍋一砸。不但社群不買單。公司內部的大佬們也紛紛離開。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過還好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">他們很快的。成立了一間黑森林工作室。並釋出了第一個目前在開源世界中。最巨大的模型Flux。這個模型的性能非常優秀。提詞控制效果也很強。建築結構。人物肢體等等。都遠勝於之前的模型。既然他這麼優秀。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">為什麼我們之前沒有介紹呢。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為flux模型非常大。所以VRAM要求也就提高了。但!!貓神伊利維亞斯在8月11號時。發布了經過壓縮的flux。並更新了forge的版本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">現在flux可以在6G VRAM上運作了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">當然要來好好介紹一下使用方法啦。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_78.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=78" target="_blank"><strong># 抽書活動</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">喔。一樣在開始之前。我們來抽書吧。這次是這本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">超有料！職場第一實用的 AI 工作術。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">用對工具讓生產力全面進化。看完這本書你再也不需要擔心。DPF檔原文Paper無法全文翻譯。會議記錄做起來費時又費力。E-mail和信息堆積了一大堆。這些都能靠AI解決。還能讓AI幫忙解釋法律用語。將數據可視化。還能在夜深人靜的時候。陪你喝心靈雞湯。AI現在已經無所不在。記得看到最後喔。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_117.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=117" target="_blank"><strong># 安裝forge</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">安裝。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">首先我們來安裝Forge吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為之前Forge停更了一段時間。導致許多功能都不能正常使用。所以Forge安裝篇的懶人包。已經變成Reforge懶人包了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Forge懶人包就這篇的底下。那就開始安裝吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到影片下方說明。找到懶人包下載文件。裡面有懶人包載點。跟目前已知沒有受影響的擴充。還有共享模型的命令。都在裡面自己看一下吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">如果不清楚怎麼用。可以參考之前的forge影片。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">下載完成後。跟我們介紹過的所有懶人包一樣。點選update更新。等系統出現請按任意鍵繼續的提示後關閉。未來要執行只需要點選run就好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過因為啟動後會自動下載模型。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">所以我們先去下載flux模型。之後放好再點run。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">另外如果你本來就有安裝forge。更新到最新版本後。會發現有些擴充不能用了。記得先整理一下。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_179.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=179" target="_blank"><strong># Flux模型下載</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">模型下載與存放路徑。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到下方說明下載經過壓縮的Flux模型。目前有兩種格式一種是FP8。另一個是NF4。雖然貓神表示如果你的顯卡是30、40系列。才能使用NF4格式。其餘的應該要下載FP8格式。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">但我們依然有看到10、20系列的顯卡。成功在NF4格式上使用的案例。再加上NF4格式VRAM需求較低。而且在比較低階的顯卡上。加速效果相當明顯。所以我們一律推薦各位使用NF4格式。真的不能使用再改用FP8格式。載好後放到以下路徑吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">對了。其實還有另一種GGUF格式。但因為需要另外下載文本編碼器跟VAE。使用起來比較麻煩。有興趣的可以到DC群中。看一下我寫的使用文章。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_236.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=236" target="_blank"><strong># Flux使用介紹</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">flux使用介紹。把Forge更新到最新版本後。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">會看到介面最上面一列。選擇模型權重存檔點的介面有改動。只要選擇UI的類型。就能知道有哪些參數需要調整。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">點選Flux。接著選擇剛剛下載的模型。Diffusion with Low Bits. 依照硬體和需求選擇儲存格式。依選擇的格式會有很大的時間差距。和些許的圖像變化。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Swap Method. 這是RAM與VRAM之間的交換方式。Asyne的速度較快。但有可能會在運作中使用過多的VRAM。從而進入共用記憶體。導致運算速度劇烈下滑。而Queue的運算方式。則是穩定的讓每一層排隊逐個進行計算。這邊我選Queue。若是還有遇到其他問題。建議到下方說明中。依利維亞斯的github上。看一下除錯方法。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_300.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再來是Swap Location。因為模型很大。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">在低vram硬體下。不足以承載模型。需要用到CPU或共用記憶體來幫忙。經過作者測試。在較新的硬體上。選擇共用記憶體交換。比使用CPU快上約百分之15。但若是系統崩潰。則建議選擇CPU交換。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">最後看到GPU Weights (MB)。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">這邊可以調整模型使用的VRAM空間。降低GPU Weights以確保繪製圖像時。有足夠的VRAM可以使用。讓低VRAM的設備。有機會挑戰更大張的圖像。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過算圖的速度也會下降。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">想要提高運算速度的話。就提高GPU Weights。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相對地若是調太高。在算圖時VRAM不夠的話。就會進到共用記憶體。大幅的拉低運算速度。這邊就依照自己的設備進行調整吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">接著看到取樣方法這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">使用原始設定的Euler 和simple(單一值)就好。或是和DPM++2M。跟SGM Uniform交互使用。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_368.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再往下看到提示詞相關性CFG這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為Flux是蒸餾模型。事實上這類模型在訓練時。並不包含CFG這類相關指標。且不適用反向提示詞。所以在繪圖時也不建議開啟。畢竟沒有效果。又要花上雙倍的時間運算。取而代之的是Distilled CFG Scale。他僅僅是稍微的改變了色澤。和些許構圖。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_402.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=402" target="_blank"><strong># 結尾</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">儘管這類模型在訓練上的硬體要求很高。社群的大家還是迅速的。訓練出各種模型。在C站上也相當的熱鬧。是個非常有展望的模型。所以說。不要怕模型太大大家沒辦法用。只要敢放出來。社群的大家。就有辦法能讓模型在馬鈴薯上運作。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">那這次的抽獎。一樣在影片上架的同時。在Discord上舉辦。如果想知道現在。大家都是怎麼拿AI來工作的。千萬不要錯過喔。艾粒現在也在跟GPT學習Blender呢。那就這樣啦。掰。</p>

<hr style="clear:both" />
====
<p>https://www.youtube.com/watch?v=Nrkh_E6iuwA</p><p>本篇為Flux的使用教學，由於flux是一個非常巨大的模型導致許多設備無法使用，在貓神lllyasviel發起的NF4格式中成功的將模型進行了大幅度的壓縮，並且在6GVRAM的設備上也能運行，快來從forge上運行Flux模型體驗新世代模型的表現能力吧。</p><p>加入Discord: https://discord.gg/TM5d89YNwA</p><p>FB粉專: https://www.facebook.com/profile.php?id=100090228987264 </p><p>成為這個頻道的會員並獲得福利： https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA/join </p><p>抖內JackEllie(本功能沒有任何福利，但謝謝你的錢): https://www.buymeacoffee.com/otakuya202y =====================================================================</p><p></p><p>0:00片頭</p><p>0:17 簡介</p><p>1:18 抽書活動</p><p>1:57 安裝forge</p><p>2:59 Flux模型下載</p><p>3:56 Flux使用介紹</p><p>6:42 結尾</p><p>7:20 片尾</p><p></p><p>=====================================================================</p><p>Forge懶人包安裝文件:</p><p>https://drive.google.com/file/d/1-2oxHAc8oJmkOhHw6O3XgtgeyMGZIKZC/view?usp=sharing</p><p></p><p>Flux模型載點</p><p>NF4格式:</p><p>https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/resolve/main/flux1-dev-bnb-nf4-v2.safetensors</p><p></p><p>FP8格式:</p><p>https://huggingface.co/lllyasviel/flux1_dev/resolve/main/flux1-dev-fp8.safetensors?download=true</p><p></p><p>GGUF格式請上Discord看教學文章</p><p>https://discord.com/channels/1077423770106597386/1273894421922058324</p><p></p><p>原文使用教學</p><p>https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981</p><p></p><p>#stablediffusion #aidrawing #ai繪圖 #aiart #aigc #SD3 #flux #nf4 #fp8 #gguf</p>]]>
      </description>
      <content:encoded><![CDATA[<hr style="clear:both" />

<p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><h1>引言：Stability AI的風波與Flux模型的誕生</h1>杰克與艾粒向觀眾們問好，並回顧了Stability AI因SD3模型遭遇的社群反彈與內部動盪。然而，他們很快便成立了黑森林工作室，並推出開源世界中體積龐大的Flux模型。Flux模型在性能和提詞控制上表現優異，超越了先前的模型，但因為其對VRAM的高要求，讓許多使用者難以使用。<h1>Flux模型的現況：6G VRAM也能玩</h1>幸運的是，貓神伊利維亞斯在8月11日釋出了壓縮版的Flux模型，並更新了Forge，使得Flux模型現在可以在6G VRAM的環境下運行。本影片將詳細介紹如何使用這個模型。<h1>抽獎活動與書籍推薦</h1>在開始之前，主持人宣布將抽出《超有料！職場第一實用的 AI 工作術》這本書，該書深入探討了如何利用AI解決辦公室中的各種問題，提升工作效率。<h1>Forge的安裝與更新</h1>由於Forge先前停止更新，導致許多擴充功能無法正常使用，影片中介紹了更新後的Forge安裝方法，以及如何下載與更新Flux模型。安裝Forge的懶人包已更新，可以在影片下方找到下載連結，並提供了擴充功能的資訊和共享模型的指令。如果對操作不熟悉，可以參考之前的Forge影片。<h1>Flux模型的下載與存放</h1>影片詳細說明了Flux模型的下載與存放路徑。目前提供FP8和NF4兩種格式，雖然貓神建議30、40系列顯卡使用NF4格式，其他顯卡使用FP8格式，但實際測試中，10、20系列的顯卡也能在NF4格式下運行。考慮到NF4格式對VRAM的需求較低，且在低階顯卡上加速效果顯著，因此影片建議優先使用NF4格式，真的不行再改用FP8格式。此外，也提到了GGUF格式，但由於使用較為複雜，需要額外下載文本編碼器和VAE，因此建議有興趣的觀眾到DC群中查看相關的使用文章。<h1>Flux模型的使用介紹</h1>影片詳細介紹了如何在Forge中設定和使用Flux模型。*   **模型權重存檔點介面：** 說明如何在Forge的介面中選擇Flux模型，以及選擇Diffusion with Low Bits模型。*   **儲存格式：** 依照硬體與需求選擇儲存格式，這將影響繪圖時間和圖像變化。*   **Swap Method：** 分別介紹了Asyne (快速但可能耗用過多VRAM) 和 Queue (穩定排隊計算) 兩種 RAM 與 VRAM 間的交換方式，建議根據硬體狀況選擇。*   **Swap Location：** 說明在低VRAM硬體上，使用共享記憶體交換或CPU交換，並提供了選擇的建議。*   **GPU Weights (MB)：** 調整模型使用的VRAM空間，以適應不同的硬體，並平衡繪圖速度和VRAM的使用。*   **取樣方法：** 建議使用原始設定的Euler 和simple(單一值)或與DPM++2M 和SGM Uniform交互使用。*   **提示詞相關性 CFG：** 因為Flux是蒸餾模型，並不適用CFG，建議使用Distilled CFG Scale。<h1>總結</h1>Flux模型在社群的努力下，即使模型體積龐大，也能在低階硬體上運行。影片鼓勵觀眾嘗試，並在Discord上舉辦抽獎活動。艾粒也透露，他們正在學習使用GPT和Blender。<hr />================================================</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><strong># 片頭</strong></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_17.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=17" target="_blank"><strong># 簡介</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">大家好我是杰克。大家好我是艾粒。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相信前陣子。大家都有吃到Stablity AI的瓜。SD3大鍋一砸。不但社群不買單。公司內部的大佬們也紛紛離開。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過還好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">他們很快的。成立了一間黑森林工作室。並釋出了第一個目前在開源世界中。最巨大的模型Flux。這個模型的性能非常優秀。提詞控制效果也很強。建築結構。人物肢體等等。都遠勝於之前的模型。既然他這麼優秀。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">為什麼我們之前沒有介紹呢。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為flux模型非常大。所以VRAM要求也就提高了。但!!貓神伊利維亞斯在8月11號時。發布了經過壓縮的flux。並更新了forge的版本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">現在flux可以在6G VRAM上運作了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">當然要來好好介紹一下使用方法啦。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_78.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=78" target="_blank"><strong># 抽書活動</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">喔。一樣在開始之前。我們來抽書吧。這次是這本。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">超有料！職場第一實用的 AI 工作術。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">用對工具讓生產力全面進化。看完這本書你再也不需要擔心。DPF檔原文Paper無法全文翻譯。會議記錄做起來費時又費力。E-mail和信息堆積了一大堆。這些都能靠AI解決。還能讓AI幫忙解釋法律用語。將數據可視化。還能在夜深人靜的時候。陪你喝心靈雞湯。AI現在已經無所不在。記得看到最後喔。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_117.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=117" target="_blank"><strong># 安裝forge</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">安裝。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">首先我們來安裝Forge吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為之前Forge停更了一段時間。導致許多功能都不能正常使用。所以Forge安裝篇的懶人包。已經變成Reforge懶人包了。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Forge懶人包就這篇的底下。那就開始安裝吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到影片下方說明。找到懶人包下載文件。裡面有懶人包載點。跟目前已知沒有受影響的擴充。還有共享模型的命令。都在裡面自己看一下吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">如果不清楚怎麼用。可以參考之前的forge影片。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">下載完成後。跟我們介紹過的所有懶人包一樣。點選update更新。等系統出現請按任意鍵繼續的提示後關閉。未來要執行只需要點選run就好。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過因為啟動後會自動下載模型。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">所以我們先去下載flux模型。之後放好再點run。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">另外如果你本來就有安裝forge。更新到最新版本後。會發現有些擴充不能用了。記得先整理一下。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_179.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=179" target="_blank"><strong># Flux模型下載</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">模型下載與存放路徑。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">到下方說明下載經過壓縮的Flux模型。目前有兩種格式一種是FP8。另一個是NF4。雖然貓神表示如果你的顯卡是30、40系列。才能使用NF4格式。其餘的應該要下載FP8格式。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">但我們依然有看到10、20系列的顯卡。成功在NF4格式上使用的案例。再加上NF4格式VRAM需求較低。而且在比較低階的顯卡上。加速效果相當明顯。所以我們一律推薦各位使用NF4格式。真的不能使用再改用FP8格式。載好後放到以下路徑吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">對了。其實還有另一種GGUF格式。但因為需要另外下載文本編碼器跟VAE。使用起來比較麻煩。有興趣的可以到DC群中。看一下我寫的使用文章。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_236.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=236" target="_blank"><strong># Flux使用介紹</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">flux使用介紹。把Forge更新到最新版本後。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">會看到介面最上面一列。選擇模型權重存檔點的介面有改動。只要選擇UI的類型。就能知道有哪些參數需要調整。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">點選Flux。接著選擇剛剛下載的模型。Diffusion with Low Bits. 依照硬體和需求選擇儲存格式。依選擇的格式會有很大的時間差距。和些許的圖像變化。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">Swap Method. 這是RAM與VRAM之間的交換方式。Asyne的速度較快。但有可能會在運作中使用過多的VRAM。從而進入共用記憶體。導致運算速度劇烈下滑。而Queue的運算方式。則是穩定的讓每一層排隊逐個進行計算。這邊我選Queue。若是還有遇到其他問題。建議到下方說明中。依利維亞斯的github上。看一下除錯方法。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_300.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再來是Swap Location。因為模型很大。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">在低vram硬體下。不足以承載模型。需要用到CPU或共用記憶體來幫忙。經過作者測試。在較新的硬體上。選擇共用記憶體交換。比使用CPU快上約百分之15。但若是系統崩潰。則建議選擇CPU交換。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">最後看到GPU Weights (MB)。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">這邊可以調整模型使用的VRAM空間。降低GPU Weights以確保繪製圖像時。有足夠的VRAM可以使用。讓低VRAM的設備。有機會挑戰更大張的圖像。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">不過算圖的速度也會下降。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">想要提高運算速度的話。就提高GPU Weights。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">相對地若是調太高。在算圖時VRAM不夠的話。就會進到共用記憶體。大幅的拉低運算速度。這邊就依照自己的設備進行調整吧。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">接著看到取樣方法這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">使用原始設定的Euler 和simple(單一值)就好。或是和DPM++2M。跟SGM Uniform交互使用。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_368.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">再往下看到提示詞相關性CFG這邊。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">因為Flux是蒸餾模型。事實上這類模型在訓練時。並不包含CFG這類相關指標。且不適用反向提示詞。所以在繪圖時也不建議開啟。畢竟沒有效果。又要花上雙倍的時間運算。取而代之的是Distilled CFG Scale。他僅僅是稍微的改變了色澤。和些許構圖。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><p><img src="https://democwise2016.github.io/action-RSS-UT/file-cache/Nrkh_E6iuwA_402.jpg" /></p></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; "><a href="https://youtu.be/Nrkh_E6iuwA&t=402" target="_blank"><strong># 結尾</strong></a></p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">儘管這類模型在訓練上的硬體要求很高。社群的大家還是迅速的。訓練出各種模型。在C站上也相當的熱鬧。是個非常有展望的模型。所以說。不要怕模型太大大家沒辦法用。只要敢放出來。社群的大家。就有辦法能讓模型在馬鈴薯上運作。</p><p style="max-width: calc(100vw - 1rem);  word-wrap: break-word; overflow-wrap: break-word; ">那這次的抽獎。一樣在影片上架的同時。在Discord上舉辦。如果想知道現在。大家都是怎麼拿AI來工作的。千萬不要錯過喔。艾粒現在也在跟GPT學習Blender呢。那就這樣啦。掰。</p>

<hr style="clear:both" />
====
<p>https://www.youtube.com/watch?v=Nrkh_E6iuwA</p><p>本篇為Flux的使用教學，由於flux是一個非常巨大的模型導致許多設備無法使用，在貓神lllyasviel發起的NF4格式中成功的將模型進行了大幅度的壓縮，並且在6GVRAM的設備上也能運行，快來從forge上運行Flux模型體驗新世代模型的表現能力吧。</p><p>加入Discord: https://discord.gg/TM5d89YNwA</p><p>FB粉專: https://www.facebook.com/profile.php?id=100090228987264 </p><p>成為這個頻道的會員並獲得福利： https://www.youtube.com/channel/UCine3_lVU-rFDRRI8xeImHA/join </p><p>抖內JackEllie(本功能沒有任何福利，但謝謝你的錢): https://www.buymeacoffee.com/otakuya202y =====================================================================</p><p></p><p>0:00片頭</p><p>0:17 簡介</p><p>1:18 抽書活動</p><p>1:57 安裝forge</p><p>2:59 Flux模型下載</p><p>3:56 Flux使用介紹</p><p>6:42 結尾</p><p>7:20 片尾</p><p></p><p>=====================================================================</p><p>Forge懶人包安裝文件:</p><p>https://drive.google.com/file/d/1-2oxHAc8oJmkOhHw6O3XgtgeyMGZIKZC/view?usp=sharing</p><p></p><p>Flux模型載點</p><p>NF4格式:</p><p>https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/resolve/main/flux1-dev-bnb-nf4-v2.safetensors</p><p></p><p>FP8格式:</p><p>https://huggingface.co/lllyasviel/flux1_dev/resolve/main/flux1-dev-fp8.safetensors?download=true</p><p></p><p>GGUF格式請上Discord看教學文章</p><p>https://discord.com/channels/1077423770106597386/1273894421922058324</p><p></p><p>原文使用教學</p><p>https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981</p><p></p><p>#stablediffusion #aidrawing #ai繪圖 #aiart #aigc #SD3 #flux #nf4 #fp8 #gguf</p>]]></content:encoded>
      <itunes:image href="https://i.ytimg.com/vi/Nrkh_E6iuwA/hqdefault.jpg"/>
      <pubDate>2024-08-19T11:00:21.000Z</pubDate>
    </item></channel>
</rss>